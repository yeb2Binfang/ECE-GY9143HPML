{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "from resnet import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainsform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding = 4),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "trainsform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root = './data', train=True, download=True, transform=trainsform_train)\n",
    "test_set = torchvision.datasets.CIFAR10(root = './data', train=False, download=True, transform=trainsform_test)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/by2034/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size = batch_size,shuffle = True, num_workers = 2)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size = batch_size, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    acc = 0\n",
    "    testacc = 0\n",
    "    totaltime = 0\n",
    "    EPOCH = 100\n",
    "    print(\"Start Training, Resnet-50!\")  # 定义遍历数据集的次数\n",
    "    \n",
    "    ts = time.time()\n",
    "    for epoch in range(EPOCH):\n",
    "        \n",
    "        print('\\nEpoch: %d' % (epoch + 1))\n",
    "        epochtime = 0\n",
    "        epochstart=time.perf_counter()\n",
    "        \n",
    "        net.train()\n",
    "        sum_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        traintime = 0.0\n",
    "        loadtime = 0.0\n",
    "        \n",
    "        \n",
    "        loadstart=time.perf_counter()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            \n",
    "            length = len(trainloader)\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            loadend=time.perf_counter()\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            trainstart=time.perf_counter()\n",
    "\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            trainend=time.perf_counter()\n",
    "            \n",
    "            sum_loss += loss.item()\n",
    "            traintime += trainend-trainstart\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels.data).cpu().sum()\n",
    "            loadtime += loadend - loadstart\n",
    "            #print(trainend - trainstart)\n",
    "            loadstart=time.perf_counter()\n",
    "        \n",
    "\n",
    "        epochend=time.perf_counter()\n",
    "        epochtime+=epochend-epochstart\n",
    "        acc = max(acc,correct/total)\n",
    "        totaltime+=epochtime\n",
    "        print(\"loss: \",sum_loss/total)\n",
    "        print(\"accuracy: \",acc)\n",
    "        #print(\"epochtime\", epochtime)\n",
    "        #print(\"traintime:\", traintime)\n",
    "        #print(\"dataloadtime:\", loadtime)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = 0.0\n",
    "            total = 0.0\n",
    "            for data in testloader:\n",
    "                net.eval()\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels.data).cpu().sum()\n",
    "            val_acc = correct/total\n",
    "            print('val_acc',val_acc)\n",
    "            t1 = time.time()\n",
    "            print('t1 time: ',t1-ts)\n",
    "            if val_acc>=0.91:\n",
    "                te = time.time()\n",
    "                print('total time: ',te-ts)\n",
    "                PATH = str(4)+\".pth\"\n",
    "            if val_acc>=0.92:\n",
    "                te = time.time()\n",
    "                print('total time: ',te-ts)\n",
    "                break\n",
    "    PATH = str(4)+\".pth\"\n",
    "    torch.save(net, PATH) \n",
    "#    print(\"average running time:\",totaltime/EPOCH)\n",
    "    print(\"best training accuracy:\",acc)\n",
    "    print(\"Training Finished, TotalEPOCH=%d\" % EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training, Resnet-50!\n",
      "\n",
      "Epoch: 1\n",
      "loss:  0.014289197936058044\n",
      "accuracy:  tensor(0.3467)\n",
      "val_acc tensor(0.4137)\n",
      "t1 time:  83.02027583122253\n",
      "\n",
      "Epoch: 2\n",
      "loss:  0.010045299323797226\n",
      "accuracy:  tensor(0.5356)\n",
      "val_acc tensor(0.5899)\n",
      "t1 time:  166.2228651046753\n",
      "\n",
      "Epoch: 3\n",
      "loss:  0.007782453709840775\n",
      "accuracy:  tensor(0.6481)\n",
      "val_acc tensor(0.6821)\n",
      "t1 time:  249.0328266620636\n",
      "\n",
      "Epoch: 4\n",
      "loss:  0.006214273574352265\n",
      "accuracy:  tensor(0.7222)\n",
      "val_acc tensor(0.7261)\n",
      "t1 time:  332.1075208187103\n",
      "\n",
      "Epoch: 5\n",
      "loss:  0.004989673699140548\n",
      "accuracy:  tensor(0.7790)\n",
      "val_acc tensor(0.7287)\n",
      "t1 time:  415.17976355552673\n",
      "\n",
      "Epoch: 6\n",
      "loss:  0.004223481510281563\n",
      "accuracy:  tensor(0.8142)\n",
      "val_acc tensor(0.7850)\n",
      "t1 time:  498.30732321739197\n",
      "\n",
      "Epoch: 7\n",
      "loss:  0.0037611090064048765\n",
      "accuracy:  tensor(0.8329)\n",
      "val_acc tensor(0.8343)\n",
      "t1 time:  581.421736240387\n",
      "\n",
      "Epoch: 8\n",
      "loss:  0.003397668759226799\n",
      "accuracy:  tensor(0.8495)\n",
      "val_acc tensor(0.8408)\n",
      "t1 time:  664.4242115020752\n",
      "\n",
      "Epoch: 9\n",
      "loss:  0.0030579580506682395\n",
      "accuracy:  tensor(0.8654)\n",
      "val_acc tensor(0.8441)\n",
      "t1 time:  747.5604848861694\n",
      "\n",
      "Epoch: 10\n",
      "loss:  0.0028402382212877274\n",
      "accuracy:  tensor(0.8742)\n",
      "val_acc tensor(0.8395)\n",
      "t1 time:  830.7608597278595\n",
      "\n",
      "Epoch: 11\n",
      "loss:  0.0025861442071199417\n",
      "accuracy:  tensor(0.8849)\n",
      "val_acc tensor(0.8691)\n",
      "t1 time:  913.8826041221619\n",
      "\n",
      "Epoch: 12\n",
      "loss:  0.002427375376522541\n",
      "accuracy:  tensor(0.8923)\n",
      "val_acc tensor(0.8556)\n",
      "t1 time:  997.0049960613251\n",
      "\n",
      "Epoch: 13\n",
      "loss:  0.0022331427043676376\n",
      "accuracy:  tensor(0.9006)\n",
      "val_acc tensor(0.8698)\n",
      "t1 time:  1080.2547523975372\n",
      "\n",
      "Epoch: 14\n",
      "loss:  0.002127703386247158\n",
      "accuracy:  tensor(0.9060)\n",
      "val_acc tensor(0.8760)\n",
      "t1 time:  1163.3269212245941\n",
      "\n",
      "Epoch: 15\n",
      "loss:  0.0020072462867200373\n",
      "accuracy:  tensor(0.9110)\n",
      "val_acc tensor(0.8840)\n",
      "t1 time:  1246.6242501735687\n",
      "\n",
      "Epoch: 16\n",
      "loss:  0.0019079114721715451\n",
      "accuracy:  tensor(0.9168)\n",
      "val_acc tensor(0.8525)\n",
      "t1 time:  1329.7174184322357\n",
      "\n",
      "Epoch: 17\n",
      "loss:  0.0017702059583365917\n",
      "accuracy:  tensor(0.9201)\n",
      "val_acc tensor(0.8899)\n",
      "t1 time:  1412.8045654296875\n",
      "\n",
      "Epoch: 18\n",
      "loss:  0.001677628131210804\n",
      "accuracy:  tensor(0.9263)\n",
      "val_acc tensor(0.8774)\n",
      "t1 time:  1495.894320487976\n",
      "\n",
      "Epoch: 19\n",
      "loss:  0.0016137029625475406\n",
      "accuracy:  tensor(0.9283)\n",
      "val_acc tensor(0.8551)\n",
      "t1 time:  1578.9295015335083\n",
      "\n",
      "Epoch: 20\n",
      "loss:  0.0015338266679644586\n",
      "accuracy:  tensor(0.9301)\n",
      "val_acc tensor(0.8831)\n",
      "t1 time:  1662.0608801841736\n",
      "\n",
      "Epoch: 21\n",
      "loss:  0.0014878925622999668\n",
      "accuracy:  tensor(0.9334)\n",
      "val_acc tensor(0.8691)\n",
      "t1 time:  1745.220510005951\n",
      "\n",
      "Epoch: 22\n",
      "loss:  0.0014126906906068324\n",
      "accuracy:  tensor(0.9374)\n",
      "val_acc tensor(0.8740)\n",
      "t1 time:  1828.351544380188\n",
      "\n",
      "Epoch: 23\n",
      "loss:  0.0013544372390955686\n",
      "accuracy:  tensor(0.9387)\n",
      "val_acc tensor(0.8984)\n",
      "t1 time:  1911.4076418876648\n",
      "\n",
      "Epoch: 24\n",
      "loss:  0.0012907212728261947\n",
      "accuracy:  tensor(0.9430)\n",
      "val_acc tensor(0.8601)\n",
      "t1 time:  1994.5134279727936\n",
      "\n",
      "Epoch: 25\n",
      "loss:  0.0012181846975535154\n",
      "accuracy:  tensor(0.9449)\n",
      "val_acc tensor(0.8899)\n",
      "t1 time:  2077.58966755867\n",
      "\n",
      "Epoch: 26\n",
      "loss:  0.0011708042748272418\n",
      "accuracy:  tensor(0.9467)\n",
      "val_acc tensor(0.8913)\n",
      "t1 time:  2160.7688131332397\n",
      "\n",
      "Epoch: 27\n",
      "loss:  0.0011727875992655753\n",
      "accuracy:  tensor(0.9474)\n",
      "val_acc tensor(0.8920)\n",
      "t1 time:  2243.835871219635\n",
      "\n",
      "Epoch: 28\n",
      "loss:  0.001107995484918356\n",
      "accuracy:  tensor(0.9512)\n",
      "val_acc tensor(0.9015)\n",
      "t1 time:  2327.01310133934\n",
      "\n",
      "Epoch: 29\n",
      "loss:  0.0010901965525746346\n",
      "accuracy:  tensor(0.9512)\n",
      "val_acc tensor(0.9025)\n",
      "t1 time:  2410.0831027030945\n",
      "\n",
      "Epoch: 30\n",
      "loss:  0.0010278613430261612\n",
      "accuracy:  tensor(0.9543)\n",
      "val_acc tensor(0.8797)\n",
      "t1 time:  2493.2090289592743\n",
      "\n",
      "Epoch: 31\n",
      "loss:  0.0010200648062303663\n",
      "accuracy:  tensor(0.9543)\n",
      "val_acc tensor(0.8869)\n",
      "t1 time:  2576.2560255527496\n",
      "\n",
      "Epoch: 32\n",
      "loss:  0.0010154213465377688\n",
      "accuracy:  tensor(0.9543)\n",
      "val_acc tensor(0.8992)\n",
      "t1 time:  2659.3171920776367\n",
      "\n",
      "Epoch: 33\n",
      "loss:  0.0009290431970357895\n",
      "accuracy:  tensor(0.9573)\n",
      "val_acc tensor(0.8845)\n",
      "t1 time:  2742.3954799175262\n",
      "\n",
      "Epoch: 34\n",
      "loss:  0.0009342496805638075\n",
      "accuracy:  tensor(0.9581)\n",
      "val_acc tensor(0.8836)\n",
      "t1 time:  2825.437795639038\n",
      "\n",
      "Epoch: 35\n",
      "loss:  0.0009179996011778712\n",
      "accuracy:  tensor(0.9581)\n",
      "val_acc tensor(0.8991)\n",
      "t1 time:  2908.553256034851\n",
      "\n",
      "Epoch: 36\n",
      "loss:  0.0008509639012813568\n",
      "accuracy:  tensor(0.9612)\n",
      "val_acc tensor(0.9066)\n",
      "t1 time:  2991.630714416504\n",
      "\n",
      "Epoch: 37\n",
      "loss:  0.0008476534698903561\n",
      "accuracy:  tensor(0.9612)\n",
      "val_acc tensor(0.8952)\n",
      "t1 time:  3074.71591258049\n",
      "\n",
      "Epoch: 38\n",
      "loss:  0.0008423658020049334\n",
      "accuracy:  tensor(0.9623)\n",
      "val_acc tensor(0.9047)\n",
      "t1 time:  3157.8032596111298\n",
      "\n",
      "Epoch: 39\n",
      "loss:  0.0008219458035565913\n",
      "accuracy:  tensor(0.9628)\n",
      "val_acc tensor(0.9014)\n",
      "t1 time:  3240.9456758499146\n",
      "\n",
      "Epoch: 40\n",
      "loss:  0.0008068546491861343\n",
      "accuracy:  tensor(0.9636)\n",
      "val_acc tensor(0.9004)\n",
      "t1 time:  3324.1338357925415\n",
      "\n",
      "Epoch: 41\n",
      "loss:  0.0007952401104941964\n",
      "accuracy:  tensor(0.9641)\n",
      "val_acc tensor(0.9093)\n",
      "t1 time:  3407.057610273361\n",
      "\n",
      "Epoch: 42\n",
      "loss:  0.0007887830395251512\n",
      "accuracy:  tensor(0.9649)\n",
      "val_acc tensor(0.9020)\n",
      "t1 time:  3490.2261924743652\n",
      "\n",
      "Epoch: 43\n",
      "loss:  0.000774971150495112\n",
      "accuracy:  tensor(0.9651)\n",
      "val_acc tensor(0.9028)\n",
      "t1 time:  3573.30259847641\n",
      "\n",
      "Epoch: 44\n",
      "loss:  0.0007499678588286042\n",
      "accuracy:  tensor(0.9657)\n",
      "val_acc tensor(0.8979)\n",
      "t1 time:  3656.415970802307\n",
      "\n",
      "Epoch: 45\n",
      "loss:  0.0007504941821098327\n",
      "accuracy:  tensor(0.9660)\n",
      "val_acc tensor(0.9074)\n",
      "t1 time:  3739.557721376419\n",
      "\n",
      "Epoch: 46\n",
      "loss:  0.0006965880461037159\n",
      "accuracy:  tensor(0.9698)\n",
      "val_acc tensor(0.9021)\n",
      "t1 time:  3822.655420780182\n",
      "\n",
      "Epoch: 47\n",
      "loss:  0.0006893850910477341\n",
      "accuracy:  tensor(0.9698)\n",
      "val_acc tensor(0.9020)\n",
      "t1 time:  3905.6978390216827\n",
      "\n",
      "Epoch: 48\n",
      "loss:  0.0006985176869481802\n",
      "accuracy:  tensor(0.9698)\n",
      "val_acc tensor(0.9105)\n",
      "t1 time:  3988.8882517814636\n",
      "total time:  3988.8882937431335\n",
      "\n",
      "Epoch: 49\n",
      "loss:  0.0006916611233539879\n",
      "accuracy:  tensor(0.9698)\n",
      "val_acc tensor(0.9142)\n",
      "t1 time:  4071.906473875046\n",
      "total time:  4071.90652012825\n",
      "\n",
      "Epoch: 50\n",
      "loss:  0.0006951722476258874\n",
      "accuracy:  tensor(0.9698)\n",
      "val_acc tensor(0.9112)\n",
      "t1 time:  4154.958126306534\n",
      "total time:  4154.958166599274\n",
      "\n",
      "Epoch: 51\n",
      "loss:  0.0006729245801270008\n",
      "accuracy:  tensor(0.9698)\n",
      "val_acc tensor(0.9125)\n",
      "t1 time:  4238.013924598694\n",
      "total time:  4238.013967037201\n",
      "\n",
      "Epoch: 52\n",
      "loss:  0.0006265325146354735\n",
      "accuracy:  tensor(0.9721)\n",
      "val_acc tensor(0.9121)\n",
      "t1 time:  4321.064021348953\n",
      "total time:  4321.064061164856\n",
      "\n",
      "Epoch: 53\n",
      "loss:  0.000627409677747637\n",
      "accuracy:  tensor(0.9722)\n",
      "val_acc tensor(0.8905)\n",
      "t1 time:  4404.103348731995\n",
      "\n",
      "Epoch: 54\n",
      "loss:  0.0006407619718462229\n",
      "accuracy:  tensor(0.9722)\n",
      "val_acc tensor(0.9143)\n",
      "t1 time:  4487.233981132507\n",
      "total time:  4487.234027147293\n",
      "\n",
      "Epoch: 55\n",
      "loss:  0.0006010088346153498\n",
      "accuracy:  tensor(0.9730)\n",
      "val_acc tensor(0.9108)\n",
      "t1 time:  4570.298453807831\n",
      "total time:  4570.2984936237335\n",
      "\n",
      "Epoch: 56\n",
      "loss:  0.0005969902982749045\n",
      "accuracy:  tensor(0.9734)\n",
      "val_acc tensor(0.9126)\n",
      "t1 time:  4653.407768726349\n",
      "total time:  4653.407811164856\n",
      "\n",
      "Epoch: 57\n",
      "loss:  0.0006281925610452891\n",
      "accuracy:  tensor(0.9734)\n",
      "val_acc tensor(0.9080)\n",
      "t1 time:  4736.514043092728\n",
      "\n",
      "Epoch: 58\n",
      "loss:  0.0005961831558682025\n",
      "accuracy:  tensor(0.9734)\n",
      "val_acc tensor(0.9067)\n",
      "t1 time:  4819.5810334682465\n",
      "\n",
      "Epoch: 59\n",
      "loss:  0.0005850191529095173\n",
      "accuracy:  tensor(0.9741)\n",
      "val_acc tensor(0.9074)\n",
      "t1 time:  4902.719349622726\n",
      "\n",
      "Epoch: 60\n",
      "loss:  0.0006169538164511323\n",
      "accuracy:  tensor(0.9741)\n",
      "val_acc tensor(0.9065)\n",
      "t1 time:  4985.7749717235565\n",
      "\n",
      "Epoch: 61\n",
      "loss:  0.000590923434458673\n",
      "accuracy:  tensor(0.9741)\n",
      "val_acc tensor(0.9103)\n",
      "t1 time:  5068.815229415894\n",
      "total time:  5068.815271854401\n",
      "\n",
      "Epoch: 62\n",
      "loss:  0.0005516914827376604\n",
      "accuracy:  tensor(0.9753)\n",
      "val_acc tensor(0.9044)\n",
      "t1 time:  5151.873697280884\n",
      "\n",
      "Epoch: 63\n",
      "loss:  0.0005559292324818671\n",
      "accuracy:  tensor(0.9756)\n",
      "val_acc tensor(0.9074)\n",
      "t1 time:  5234.95863699913\n",
      "\n",
      "Epoch: 64\n",
      "loss:  0.0005904966284520924\n",
      "accuracy:  tensor(0.9756)\n",
      "val_acc tensor(0.9158)\n",
      "t1 time:  5318.044560432434\n",
      "total time:  5318.04460144043\n",
      "\n",
      "Epoch: 65\n",
      "loss:  0.0005285604685731232\n",
      "accuracy:  tensor(0.9764)\n",
      "val_acc tensor(0.9138)\n",
      "t1 time:  5401.133562326431\n",
      "total time:  5401.1336052417755\n",
      "\n",
      "Epoch: 66\n",
      "loss:  0.0005511715389974416\n",
      "accuracy:  tensor(0.9764)\n",
      "val_acc tensor(0.8927)\n",
      "t1 time:  5484.171964883804\n",
      "\n",
      "Epoch: 67\n",
      "loss:  0.0005423653291352093\n",
      "accuracy:  tensor(0.9764)\n",
      "val_acc tensor(0.9168)\n",
      "t1 time:  5567.221350431442\n",
      "total time:  5567.22139954567\n",
      "\n",
      "Epoch: 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0005641663511656225\n",
      "accuracy:  tensor(0.9764)\n",
      "val_acc tensor(0.9160)\n",
      "t1 time:  5650.280206441879\n",
      "total time:  5650.280246734619\n",
      "\n",
      "Epoch: 69\n",
      "loss:  0.0005473402734845876\n",
      "accuracy:  tensor(0.9764)\n",
      "val_acc tensor(0.9155)\n",
      "t1 time:  5733.3425879478455\n",
      "total time:  5733.342626571655\n",
      "\n",
      "Epoch: 70\n",
      "loss:  0.0005042093744315207\n",
      "accuracy:  tensor(0.9781)\n",
      "val_acc tensor(0.9159)\n",
      "t1 time:  5816.393316745758\n",
      "total time:  5816.393356323242\n",
      "\n",
      "Epoch: 71\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir \"./data_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  test_imgs.zip\n",
      "  inflating: ./data_test/Test_img/8/04.jpg  \n",
      "  inflating: ./data_test/Test_img/3/01.jpg  \n",
      "  inflating: ./data_test/Test_img/2/04.jpg  \n",
      "  inflating: ./data_test/Test_img/5/00.jpg  \n",
      "  inflating: ./data_test/Test_img/4/02.jpg  \n",
      "  inflating: ./data_test/Test_img/7/04.jpg  \n",
      "  inflating: ./data_test/Test_img/3/00.jpg  \n",
      "  inflating: ./data_test/Test_img/5/04.jpg  \n",
      "  inflating: ./data_test/Test_img/5/03.jpg  \n",
      "  inflating: ./data_test/Test_img/2/00.jpg  \n",
      "  inflating: ./data_test/Test_img/5/02.jpg  \n",
      "  inflating: ./data_test/Test_img/3/02.jpg  \n",
      "  inflating: ./data_test/Test_img/8/00.jpg  \n",
      "  inflating: ./data_test/Test_img/4/04.jpg  \n",
      "  inflating: ./data_test/Test_img/7/03.jpg  \n",
      "  inflating: ./data_test/Test_img/1/04.jpg  \n",
      "  inflating: ./data_test/Test_img/4/03.jpg  \n",
      "  inflating: ./data_test/Test_img/8/03.jpg  \n",
      "  inflating: ./data_test/Test_img/8/02.jpg  \n",
      "  inflating: ./data_test/Test_img/1/01.jpg  \n",
      "  inflating: ./data_test/Test_img/2/02.jpg  \n",
      "  inflating: ./data_test/Test_img/2/01.jpg  \n",
      "  inflating: ./data_test/Test_img/3/04.jpg  \n",
      "  inflating: ./data_test/Test_img/5/01.jpg  \n",
      "  inflating: ./data_test/Test_img/1/02.jpg  \n",
      "  inflating: ./data_test/Test_img/6/00.jpg  \n",
      "  inflating: ./data_test/Test_img/1/00.jpg  \n",
      "  inflating: ./data_test/Test_img/0/00.jpg  \n",
      "  inflating: ./data_test/Test_img/6/04.jpg  \n",
      "  inflating: ./data_test/Test_img/0/03.jpg  \n",
      "  inflating: ./data_test/Test_img/9/04.jpg  \n",
      "  inflating: ./data_test/Test_img/9/03.jpg  \n",
      "  inflating: ./data_test/Test_img/6/03.jpg  \n",
      "  inflating: ./data_test/Test_img/3/03.jpg  \n",
      "  inflating: ./data_test/Test_img/7/01.jpg  \n",
      "  inflating: ./data_test/Test_img/6/01.jpg  \n",
      "  inflating: ./data_test/Test_img/9/02.jpg  \n",
      "  inflating: ./data_test/Test_img/4/00.jpg  \n",
      "  inflating: ./data_test/Test_img/7/02.jpg  \n",
      "  inflating: ./data_test/Test_img/6/02.jpg  \n",
      "  inflating: ./data_test/Test_img/2/03.jpg  \n",
      "  inflating: ./data_test/Test_img/1/03.jpg  \n",
      "  inflating: ./data_test/Test_img/9/01.jpg  \n",
      "  inflating: ./data_test/Test_img/0/02.jpg  \n",
      "  inflating: ./data_test/Test_img/7/00.jpg  \n",
      "  inflating: ./data_test/Test_img/0/04.jpg  \n",
      "  inflating: ./data_test/Test_img/9/00.jpg  \n",
      "  inflating: ./data_test/Test_img/0/01.jpg  \n",
      "  inflating: ./data_test/Test_img/4/01.jpg  \n",
      "  inflating: ./data_test/Test_img/8/01.jpg  \n"
     ]
    }
   ],
   "source": [
    "!unzip \"test_imgs.zip\" -d \"./data_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_path = \"3.pth\"\n",
    "net = torch.load(net_path)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation():\n",
    "    img_index = [\"00.jpg\", \"01.jpg\", \"02.jpg\", \"03.jpg\", \"04.jpg\"]\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 50\n",
    "    for i in range(10):\n",
    "        for iidex in img_index:\n",
    "            img_path = \"./data_test/Test_img\" + \"/\"+str(i)+\"/\" + iidex\n",
    "            #img_path += \"/\"+str(i)+\"/\" + iidex\n",
    "            #print(img_path)\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize((32, 32), Image.BILINEAR)\n",
    "            img = np.array(img)\n",
    "            img = trainsform_val(img)\n",
    "            img = torch.unsqueeze(img, 0)\n",
    "            img = img.to(device)\n",
    "            label = i\n",
    "            outputs = net(img)\n",
    "            outputs = F.softmax(outputs, dim = 1)\n",
    "            pred = torch.max(outputs, dim = 1)\n",
    "            if pred[1].item() == label:\n",
    "                correct += 1\n",
    "    print(\"The accuracy is \", correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is  0.94\n"
     ]
    }
   ],
   "source": [
    "evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027129319932501072"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std([1.0,0.96,0.92,0.94,0.94])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
